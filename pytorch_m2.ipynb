{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_m2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIXQtd2W6Zjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv8CyVWeNFBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOt52iC36KPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "MNIST_PATH = 'mnist_28.pkl.gz'\n",
        "\n",
        "def load_mnist(path):\n",
        "    \n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        u = pickle._Unpickler(f)\n",
        "        u.encoding = 'latin1'\n",
        "        train, valid, test = u.load()\n",
        "\n",
        "    train_x, train_y = train\n",
        "    valid_x, valid_y = valid\n",
        "    test_x,  test_y  = test        \n",
        "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "# Loads data where data is split into class labels\n",
        "def load_mnist_split(path = MNIST_PATH):\n",
        "    train_x, train_y, valid_x, valid_y, test_x, test_y = load_mnist(path)\n",
        "    \n",
        "    def split_by_class(x, y, num_classes):\n",
        "        result_x = [0]*num_classes\n",
        "        result_y = [0]*num_classes\n",
        "        for i in range(num_classes):\n",
        "            idx_i = np.where(y == i)[0]\n",
        "            result_x[i] = x[idx_i]\n",
        "            result_y[i] = y[idx_i]\n",
        "        return result_x, result_y\n",
        "      \n",
        "    train_x, train_y = split_by_class(train_x, train_y, 10)\n",
        "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "def create_semisupervised(x, y, n_labeled):\n",
        "    n_x = x[0].shape[0]\n",
        "    n_classes = 10\n",
        "    if n_labeled % n_classes != 0: \n",
        "        raise(\"n_labeled (wished number of labeled samples) not divisible by n_classes (number of classes)\")\n",
        "    n_labels_per_class = n_labeled//n_classes\n",
        "    x_labeled = [0]*n_classes\n",
        "    x_unlabeled = [0]*n_classes\n",
        "    y_labeled = [0]*n_classes\n",
        "    y_unlabeled = [0]*n_classes\n",
        "    #p=range(10)#10% error\n",
        "    #p=list(p)#10% error\n",
        "    #random.shuffle(p)#10% error\n",
        "    for i in range(n_classes):\n",
        "        idx = range(x[i].shape[0])\n",
        "        random.seed(1412)\n",
        "        idx=list(idx)\n",
        "        random.shuffle(idx)\n",
        "        x_labeled[i]   = x[i][idx[:n_labels_per_class]]\n",
        "        y_labeled[i]   = y[i][idx[:n_labels_per_class]]\n",
        "     #   y_labeled[i][0]=p[i]#10% error\n",
        "        x_unlabeled[i] = x[i][idx[n_labels_per_class:]]\n",
        "        y_unlabeled[i] = y[i][idx[n_labels_per_class:]]\n",
        "    return np.vstack(x_labeled), np.hstack(y_labeled), np.vstack(x_unlabeled), np.hstack(y_unlabeled)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "q0kyWQO8tPbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(data, batch_size, num_epoch, shuffle = True):\n",
        "    data = list(data)\n",
        "    data = np.array(data)\n",
        "    data_size = data.shape[0]\n",
        "    num_batches_per_epoch = (data_size + batch_size - 1)//batch_size\n",
        "    for epoch in range(num_epoch):\n",
        "        if shuffle:\n",
        "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "            shuffled_data = data[shuffle_indices]\n",
        "        else:\n",
        "            shuffled_data = data\n",
        "\n",
        "        for batch_idx in range(num_batches_per_epoch):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx   = min((batch_idx + 1)*batch_size, data_size)\n",
        "            yield(shuffled_data[start_idx:end_idx])\n",
        "            \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1dusq1rPEPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "data_size = 50000\n",
        "batch_size = 100\n",
        "n_batch_size=100\n",
        "n_labelled = 100\n",
        "n_epoch = 10\n",
        "max_iter = n_epoch*(data_size-n_labelled)//n_batch_size\n",
        "\n",
        "# load data from mnist\n",
        "train_x, train_y, valid_x, valid_y, test_x, test_y = load_mnist_split()\n",
        "# split training set\n",
        "data_x_l, data_y_l, data_x_u, data_y_u = create_semisupervised(train_x, train_y, n_labelled)\n",
        "data_x_u=torch.FloatTensor(data_x_u)\n",
        "data_y_l=torch.LongTensor(data_y_l)\n",
        "data_y_u=torch.LongTensor(data_y_u)\n",
        "data_x_l=torch.FloatTensor(data_x_l)\n",
        "test_x=torch.FloatTensor(test_x)\n",
        "test_y=torch.LongTensor(test_y)\n",
        "unlabelled_dataset=TensorDataset(data_x_u, data_y_u)\n",
        "u_loader=DataLoader(dataset=unlabelled_dataset, batch_size=100, shuffle=True)\n",
        "test_dataset=TensorDataset(test_x, test_y)\n",
        "test_loader=DataLoader(dataset=test_dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-usrRdB8Q81U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8f2576c-d4f4-421d-f596-83938760ee59"
      },
      "source": [
        "for x,y in u_loader:\n",
        "        print(x.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n",
            "torch.Size([100, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVEv_HIg6kCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class M2(nn.Module):\n",
        "    def __init__(self, x_dim,y_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(M2, self).__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        self.fc1 = nn.Linear(x_dim+y_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(z_dim+y_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "        self.fc7 = nn.Linear(x_dim,h_dim1)\n",
        "        self.fc8 = nn.Linear(h_dim1,y_dim)\n",
        "    def encoder(self, x,y):#p(z|x,y)\n",
        "        t=torch.cat((x,y),1)\n",
        "        h =F.softplus(self.fc1(t))\n",
        "        h = F.softplus(self.fc2(h))\n",
        "        mu0=self.fc31(h)\n",
        "        logvar=self.fc32(h) \n",
        "        return mu0, logvar\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z,y):\n",
        "        t=torch.cat((z,y),1)\n",
        "        h = F.softplus(self.fc4(t))\n",
        "        h =F.softplus(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    def classify(self,x):\n",
        "        h=F.softplus(self.fc7(x))\n",
        "        y_pred=F.softmax(self.fc8(h),dim=-1)\n",
        "        return y_pred\n",
        "    def predict(self,x):\n",
        "        logits_=self.classify(x)\n",
        "        y_p=logits_.detach().cpu().numpy()\n",
        "        return np.argmax(y_p,axis=1)\n",
        "    def forward(self, x,y):\n",
        "        mu,log_var= self.encoder(x.view(-1, 784),y)\n",
        "        z = self.sampling(mu, log_var)\n",
        "        x_recon=self.decoder(z,y)\n",
        "        return x_recon,z, mu, log_var\n",
        "\n",
        "# build model\n",
        "vae = M2(x_dim=784,y_dim=10, h_dim1= 512, h_dim2=512, z_dim=50)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1xZR8LLI2g5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XcZHXpv7ErS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(vae.parameters(),lr=0.001)\n",
        "# return reconstruction error + KL divergence losses\n",
        "n_cluster=10\n",
        "def L(x, x_recon, y, mu, logvar):\n",
        "  \n",
        "    def KLD(mu,logvar):\n",
        "        return - 0.5*(1+logvar-mu.pow(2)-torch.exp(logvar))\n",
        "    def log_bernoulli(p, x):\n",
        "        epsilon = 1e-7\n",
        "        return x * torch.log(p + epsilon) + (1-x) * torch.log(1-p + epsilon)\n",
        "        \n",
        "        # uniform dist\n",
        "    prior_y = (1. / n_cluster) * torch.ones_like( y )\n",
        "    logpy = - torch.sum(y * torch.log(prior_y + 1e-8), dim=1)\n",
        "\n",
        "        # (batch_size, z_dim) -> batch_size\n",
        "    kldloss = torch.sum(KLD(mu, logvar),1)\n",
        "        # (batch_size, 784) -> batch_size,\n",
        "    logpx   = torch.sum(log_bernoulli(x_recon, x), 1)\n",
        "        \n",
        "    loss = kldloss - logpx - logpy\n",
        "    return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuCAowckn4S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9QshXqd7dno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha=0.1*100\n",
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for data,_ in u_loader:\n",
        "        data = data.to(device)\n",
        "        y_l_onehot=torch.zeros(n_labelled, n_cluster).scatter_(1, data_y_l.view(-1,1), 1)\n",
        "        y_l_onehot=y_l_onehot.to(device)\n",
        "        data_l=data_x_l.to(device)\n",
        "#\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        x_recon_l,z_l, mu_l, log_var_l = vae(data_l,y_l_onehot)\n",
        "        loss_L =  L(data_l, x_recon_l, y_l_onehot, mu_l, log_var_l)#labelled loss\n",
        "        # encoder, unlabelled data\n",
        "        z_u      = [0]*n_cluster\n",
        "        mu_u     = [0]*n_cluster\n",
        "        logvar_u =[0]*n_cluster\n",
        "        y_us = []\n",
        "        u=[]\n",
        "        for i in range(n_cluster):\n",
        "            _y = i * torch.ones(batch_size,1)\n",
        "            y_us.append(torch.zeros(batch_size, n_cluster).scatter_(1, _y.long(), 1))\n",
        "            y_u_onehot=y_us[i].to(device)\n",
        "            x_recon_u,z_u, mu_u, log_var_u = vae(data,y_u_onehot)\n",
        "\n",
        "            u.append(L(data, x_recon_u, y_u_onehot, mu_u, log_var_u).view(-1,1))#unlabelled loss\n",
        "        #print(\"u\",u)\n",
        "        loss_u=torch.cat(u,1)\n",
        "        #print(\"loss_u\",loss_u)\n",
        "        y_u_prob=vae.classify(data)\n",
        "        U=torch.mul(y_u_prob, torch.sub(loss_u, -torch.log(y_u_prob+1e-8)))\n",
        "        U_sum=U.sum(1)\n",
        "        # Add auxiliary classification loss q(y|x)\n",
        "        logits = vae.classify(data_l)\n",
        "        \n",
        "        # Regular cross entropy\n",
        "        classication_loss = -torch.sum(y_l_onehot* torch.log(logits + 1e-8), dim=1).mean()\n",
        "\n",
        "        loss =torch.mean(loss_L) +alpha * classication_loss + U_sum.mean()\n",
        "\n",
        "       \n",
        "        \n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(u_loader.dataset)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e66EyXem7hlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def test(loader):\n",
        "    vae.eval()\n",
        "    \n",
        "    pre=[]\n",
        "    tru=[]\n",
        " \n",
        "    with torch.no_grad():\n",
        "        for data, y in loader:\n",
        "            data = data.cuda()\n",
        "            tru.append(y.numpy())\n",
        "            \n",
        "            pre.append(vae.predict(data))\n",
        "    tru=np.concatenate(tru,0)\n",
        "    pre=np.concatenate(pre,0)\n",
        "    print(accuracy_score(tru,pre))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBgombU67k0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e37500d-c49c-4ac5-d472-7d353537b5e0"
      },
      "source": [
        "for epoch in range(1, 51):\n",
        "    train(epoch)\n",
        "    print(\"train acc\")\n",
        "    test(u_loader)\n",
        "    print(\"test acc\")\n",
        "    test(test_loader)\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average loss: 3.2859\n",
            "train acc\n",
            "0.7362925851703407\n",
            "test acc\n",
            "0.7433\n",
            "====> Epoch: 2 Average loss: 2.1309\n",
            "train acc\n",
            "0.7554108216432865\n",
            "test acc\n",
            "0.7571\n",
            "====> Epoch: 3 Average loss: 1.8779\n",
            "train acc\n",
            "0.7585170340681363\n",
            "test acc\n",
            "0.7575\n",
            "====> Epoch: 4 Average loss: 1.7961\n",
            "train acc\n",
            "0.762184368737475\n",
            "test acc\n",
            "0.7599\n",
            "====> Epoch: 5 Average loss: 1.7560\n",
            "train acc\n",
            "0.7659919839679359\n",
            "test acc\n",
            "0.7609\n",
            "====> Epoch: 6 Average loss: 1.7286\n",
            "train acc\n",
            "0.7634869739478958\n",
            "test acc\n",
            "0.7584\n",
            "====> Epoch: 7 Average loss: 1.7065\n",
            "train acc\n",
            "0.7834869739478958\n",
            "test acc\n",
            "0.7797\n",
            "====> Epoch: 8 Average loss: 1.6890\n",
            "train acc\n",
            "0.786813627254509\n",
            "test acc\n",
            "0.7831\n",
            "====> Epoch: 9 Average loss: 1.6734\n",
            "train acc\n",
            "0.7970541082164329\n",
            "test acc\n",
            "0.7931\n",
            "====> Epoch: 10 Average loss: 1.6603\n",
            "train acc\n",
            "0.7987374749498998\n",
            "test acc\n",
            "0.7948\n",
            "====> Epoch: 11 Average loss: 1.6481\n",
            "train acc\n",
            "0.8164128256513026\n",
            "test acc\n",
            "0.811\n",
            "====> Epoch: 12 Average loss: 1.6377\n",
            "train acc\n",
            "0.8224048096192385\n",
            "test acc\n",
            "0.8209\n",
            "====> Epoch: 13 Average loss: 1.6277\n",
            "train acc\n",
            "0.8303006012024048\n",
            "test acc\n",
            "0.8317\n",
            "====> Epoch: 14 Average loss: 1.6184\n",
            "train acc\n",
            "0.8247695390781563\n",
            "test acc\n",
            "0.8207\n",
            "====> Epoch: 15 Average loss: 1.6103\n",
            "train acc\n",
            "0.8319238476953907\n",
            "test acc\n",
            "0.8283\n",
            "====> Epoch: 16 Average loss: 1.6026\n",
            "train acc\n",
            "0.8382765531062124\n",
            "test acc\n",
            "0.8355\n",
            "====> Epoch: 17 Average loss: 1.5960\n",
            "train acc\n",
            "0.8437274549098196\n",
            "test acc\n",
            "0.842\n",
            "====> Epoch: 18 Average loss: 1.5890\n",
            "train acc\n",
            "0.8407214428857716\n",
            "test acc\n",
            "0.8371\n",
            "====> Epoch: 19 Average loss: 1.5832\n",
            "train acc\n",
            "0.8461322645290581\n",
            "test acc\n",
            "0.8412\n",
            "====> Epoch: 20 Average loss: 1.5769\n",
            "train acc\n",
            "0.8507414829659319\n",
            "test acc\n",
            "0.8492\n",
            "====> Epoch: 21 Average loss: 1.5706\n",
            "train acc\n",
            "0.8531062124248497\n",
            "test acc\n",
            "0.8513\n",
            "====> Epoch: 22 Average loss: 1.5647\n",
            "train acc\n",
            "0.8586573146292585\n",
            "test acc\n",
            "0.8569\n",
            "====> Epoch: 23 Average loss: 1.5585\n",
            "train acc\n",
            "0.8600400801603206\n",
            "test acc\n",
            "0.8603\n",
            "====> Epoch: 24 Average loss: 1.5542\n",
            "train acc\n",
            "0.8621643286573146\n",
            "test acc\n",
            "0.862\n",
            "====> Epoch: 25 Average loss: 1.5494\n",
            "train acc\n",
            "0.8639078156312625\n",
            "test acc\n",
            "0.8647\n",
            "====> Epoch: 26 Average loss: 1.5451\n",
            "train acc\n",
            "0.8664128256513026\n",
            "test acc\n",
            "0.8677\n",
            "====> Epoch: 27 Average loss: 1.5404\n",
            "train acc\n",
            "0.8671142284569139\n",
            "test acc\n",
            "0.8688\n",
            "====> Epoch: 28 Average loss: 1.5369\n",
            "train acc\n",
            "0.8705210420841684\n",
            "test acc\n",
            "0.87\n",
            "====> Epoch: 29 Average loss: 1.5336\n",
            "train acc\n",
            "0.8709819639278558\n",
            "test acc\n",
            "0.8708\n",
            "====> Epoch: 30 Average loss: 1.5300\n",
            "train acc\n",
            "0.87312625250501\n",
            "test acc\n",
            "0.8734\n",
            "====> Epoch: 31 Average loss: 1.5257\n",
            "train acc\n",
            "0.8743286573146293\n",
            "test acc\n",
            "0.8761\n",
            "====> Epoch: 32 Average loss: 1.5228\n",
            "train acc\n",
            "0.8760921843687375\n",
            "test acc\n",
            "0.876\n",
            "====> Epoch: 33 Average loss: 1.5199\n",
            "train acc\n",
            "0.8745891783567135\n",
            "test acc\n",
            "0.8748\n",
            "====> Epoch: 34 Average loss: 1.5163\n",
            "train acc\n",
            "0.8752905811623246\n",
            "test acc\n",
            "0.8744\n",
            "====> Epoch: 35 Average loss: 1.5133\n",
            "train acc\n",
            "0.8783166332665331\n",
            "test acc\n",
            "0.878\n",
            "====> Epoch: 36 Average loss: 1.5107\n",
            "train acc\n",
            "0.8816633266533066\n",
            "test acc\n",
            "0.8835\n",
            "====> Epoch: 37 Average loss: 1.5079\n",
            "train acc\n",
            "0.8784769539078157\n",
            "test acc\n",
            "0.8784\n",
            "====> Epoch: 38 Average loss: 1.5052\n",
            "train acc\n",
            "0.8798597194388778\n",
            "test acc\n",
            "0.8817\n",
            "====> Epoch: 39 Average loss: 1.5036\n",
            "train acc\n",
            "0.8819839679358717\n",
            "test acc\n",
            "0.882\n",
            "====> Epoch: 40 Average loss: 1.5003\n",
            "train acc\n",
            "0.8818837675350701\n",
            "test acc\n",
            "0.8809\n",
            "====> Epoch: 41 Average loss: 1.4980\n",
            "train acc\n",
            "0.8833066132264529\n",
            "test acc\n",
            "0.8834\n",
            "====> Epoch: 42 Average loss: 1.4951\n",
            "train acc\n",
            "0.8843687374749499\n",
            "test acc\n",
            "0.8828\n",
            "====> Epoch: 43 Average loss: 1.4933\n",
            "train acc\n",
            "0.886312625250501\n",
            "test acc\n",
            "0.8864\n",
            "====> Epoch: 44 Average loss: 1.4915\n",
            "train acc\n",
            "0.8834268537074148\n",
            "test acc\n",
            "0.8821\n",
            "====> Epoch: 45 Average loss: 1.4889\n",
            "train acc\n",
            "0.8833066132264529\n",
            "test acc\n",
            "0.882\n",
            "====> Epoch: 46 Average loss: 1.4869\n",
            "train acc\n",
            "0.8857114228456914\n",
            "test acc\n",
            "0.8857\n",
            "====> Epoch: 47 Average loss: 1.4847\n",
            "train acc\n",
            "0.8875150300601202\n",
            "test acc\n",
            "0.8873\n",
            "====> Epoch: 48 Average loss: 1.4839\n",
            "train acc\n",
            "0.8871543086172344\n",
            "test acc\n",
            "0.8866\n",
            "====> Epoch: 49 Average loss: 1.4812\n",
            "train acc\n",
            "0.887995991983968\n",
            "test acc\n",
            "0.8863\n",
            "====> Epoch: 50 Average loss: 1.4801\n",
            "train acc\n",
            "0.888817635270541\n",
            "test acc\n",
            "0.8901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GT4diwftZIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "100e913e-4511-408e-d4c6-c6930fcff94f"
      },
      "source": [
        "y_us=[]\n",
        "_y = 1 * torch.ones(batch_size,1)\n",
        "y_us.append(torch.zeros(batch_size, n_cluster).scatter_(1, _y.long(), 1))\n",
        "y_u_onehot=y_us[i].to(device)\n",
        "#x_recon_u,z_u, mu_u, log_var_u = vae(data_l,y_u_onehot)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-816bf9d00f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_us\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_u_onehot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_us\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#x_recon_u,z_u, mu_u, log_var_u = vae(data_l,y_u_onehot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn95KdITnTrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_us = []\n",
        "u=[]\n",
        "for i in range(n_cluster):\n",
        "  _y = i * torch.ones(batch_size,1)\n",
        "  #y_us.append(torch.zeros(batch_size, n_cluster).scatter_(1, _y, 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibGaXDoqqYUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.ones(batch_size,1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}